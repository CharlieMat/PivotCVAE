{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "```\n",
    "> conda create -n genslate python=3.6\n",
    "> conda activate genslate\n",
    "> conda install pip\n",
    "> conda install ipykernel\n",
    "> python -m ipykernel install --user --name genslate --display-name \"GenSlate\"\n",
    "> conda install pytorch==1.7.0 torchvision==0.8.0 cudatoolkit=9.2 -c pytorch\n",
    "> conda install -c conda-forge scikit-learn\n",
    "> conda isntall tqdm setproctitle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Simulation Environment\n",
    "\n",
    "See corresponding [notebook](Dataset%20and%20Simulation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment\n",
    "\n",
    "General process:\n",
    "* Real-world data: pretrain response model on entire set --> train generative model on training set --> evaluate on test set\n",
    "* Simulation: generate dataset from simulator --> pretrain response model on train+val set --> train generative model on train set --> evaluate on test set\n",
    "\n",
    "Basic commands:\n",
    "\n",
    "DATASET COMMAND examples:\n",
    "\n",
    "* Yoochoose:\n",
    "```\n",
    "> --dataset yoochoose --nouser\n",
    "> --dataset movielens\n",
    "> --dataset movielens --nouser\n",
    "```\n",
    "\n",
    "* Simulation:\n",
    "```\n",
    "> --dataset urm --n_user 1000 --n_item 3000 --n_train 100000 --n_val 10000 --n_test 10000\n",
    "> --dataset urmp --n_user 1000 --n_item 3000 --n_train 100000 --n_val 10000 --n_test 10000\n",
    "> --dataset urmpmr --n_user 1000 --n_item 3000 --n_train 100000 --n_val 10000 --n_test 10000 --mr_factor 0.2\n",
    "```\n",
    "\n",
    "TRAINING COMMAND examples:\n",
    "\n",
    "```\n",
    "> --batch_size 64 --lr 0.001 --wdecay 0.001 --device cuda:0\n",
    "> --batch_size 64 --lr 0.001 --wdecay 0.001 --device cuda:0 --nneg 100\n",
    "```\n",
    "\n",
    "\n",
    "### 1.1 Pretrain user response model from dataset\n",
    "\n",
    "RESP MODEL COMMAND list:\n",
    "* dim: embedding dimension size\n",
    "* resp_struct: mlp structure as list of layer size\n",
    "\n",
    "```\n",
    "> python pretrain_env.py [DATASET COMMAND] [RESP MODEL COMMAND] [TRAINING COMMAND]\n",
    "> python pretrain_env.py --dataset yoochoose --s 5 --nouser --dim 8 --resp_struct [40,256,256,5] --epoch 10 --batch_size 64 --lr 0.001 --wdecay 0.001 --device cuda:0\n",
    "> python pretrain_env.py --dataset movielens --s 5 --dim 8 --resp_struct [48,256,256,5] --epoch 10 --batch_size 64 --lr 0.001 --wdecay 0.001 --device cuda:0\n",
    "> python pretrain_env.py --dataset movielens --s 5 --nouser --dim 8 --resp_struct [40,256,256,5] --batch_size 64 --lr 0.001 --wdecay 0.001 --device cuda:0\n",
    "> python pretrain_env.py --dataset urmp --sim_dim 8 --n_user 1000 --n_item 3000 --n_train 100000 --n_val 10000 --n_test 10000 --pbias_min=-0.2 --pbias_max 0.2 --dim 8 --resp_struct [48,256,256,5] --epoch 10 --batch_size 64 --lr 0.001 --wdecay 0.001 --device cuda:0\n",
    "> python pretrain_env.py --dataset urmpmr --sim_dim 8 --n_user 1000 --n_item 3000 --n_train 100000 --n_val 10000 --n_test 10000 --pbias_min=-0.2 --pbias_max 0.2 --mr_factor 0.2 --dim 8 --resp_struct [48,256,256,5] --batch_size 64 --lr 0.001 --wdecay 0.001 --device cuda:0\n",
    "```\n",
    "\n",
    "\n",
    "### 1.2 Train generative model:\n",
    "\n",
    "ENVIRONMENT COMMAND list:\n",
    "* resp_path: saved response model path\n",
    "\n",
    "MODEL COMMAND examples: (+8 for the first dim of each struct when --nouser flag is off)\n",
    "```\n",
    "> --model listcvae --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --dec_struct [22,256,256,40] --prior_struct [6,128,128] --mask_train\n",
    "> --model pivotcvae --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --psm_struct [22,256,256,8] --scm_struct [30,256,256,32] --prior_struct [6,128,128] --mask_train\n",
    "> --model pivotcvae_sgt_pi --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --psm_struct [22,256,256,8] --scm_struct [30,256,256,32] --prior_struct [6,128,128] --mask_train\n",
    "> --model pivotcvae_sgt_pi --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --psm_struct [22,256,256,8] --scm_struct [30,256,256,32] --prior_struct [6,128,128] --mask_train\n",
    "> --model pivotcvae_sgt_pi --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --psm_struct [22,256,256,8] --scm_struct [30,256,256,32] --prior_struct [6,128,128] --mask_train\n",
    "```\n",
    "\n",
    "Format:\n",
    "```\n",
    "> python train_generative.py [DATASET COMMAND] [ENVIRONMENT COMMAND] [MODEL COMMAND] [TRAINING COMMAND] --beta 0.001\n",
    "```\n",
    "\n",
    "Example 1: \n",
    "* Environment: yoochoose\n",
    "* Model: listcvae\n",
    "\n",
    "```\n",
    "> python train_generative.py --dataset yoochoose --nouser --resp_path resp/yoochoose_nouser/resp_[40,256,256,5]_dim8_BS64_lr0.00100_decay0.00100 --model listcvae --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --dec_struct [22,256,256,40] --prior_struct [6,128,128] --mask_train --batch_size 64 --lr 0.0003 --wdecay 0.0 --device cuda:3 --nneg 1000 --beta 0.001\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "--resp_path resp/resp_[48,256,256,5]_yoochoose_nouser_BS64_dim8_lr0.00100_decay0.00010\n",
    "```\n",
    "\n",
    "MODEL COMMAND:\n",
    "\n",
    "* ListCVAE\n",
    "```\n",
    "> --model listcvaewithprior --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --dec_struct [22,256,256,40] --prior_struct [6,128,128]\n",
    "```\n",
    "\n",
    "* PivotCVAE / PivotCVAEPrePermute\n",
    "```\n",
    "> --model pivotcvae --dim 8 --z_size 16 --s 5 --enc_struct [46,256,256] --psm_struct [22,256,256,8] --scm_struct [30,256,256,32] --prior_struct [6,128,128]\n",
    "```\n",
    "\n",
    "### 1.3 Beta search for a type of model: \n",
    "\n",
    "Use the same command in previous section, but set \"--beta\" to -1. This will iterate through the following beta values\n",
    "> \\[0.00001, 0.00003, 0.0001, 0.0003\\] + \n",
    "> \\[0.0005 + 0.0001 * i for i in range(5)\\] +\n",
    "> \\[0.001 + 0.001 * i for i in range(10)\\] +\n",
    "> \\[0.012 + 0.002 * i for i in range(10)\\] + \n",
    "> \\[0.1, 0.3, 1.0, 3.0, 10.0, 30.0\\])\n",
    "\n",
    "To change the beta list, check settings.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Example\n",
    "\n",
    "Yoochoose with ListCVAEWithPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.204864025115967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def ms2str(ms):\n",
    "    seconds=int(ms/1000)%60\n",
    "    minutes=int(ms/(1000*60))%60\n",
    "    hours=int(ms/(1000*60*60))%24\n",
    "    days=int(ms/(1000*60*60*24))\n",
    "    return str(days) + \"d\" + str(hours) + \"h\" + str(minutes) + \"m\" + str(seconds) + \"s\"\n",
    "ms2str(360000000)\n",
    "import torch\n",
    "A = torch.randn(100,3000).to(\"cuda:1\")\n",
    "B = torch.randn(3000,200).to(\"cuda:1\")\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "C = torch.mm(A,B)\n",
    "end.record()\n",
    "print(start.elapsed_time(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "### 2.1 Single Model\n",
    "\n",
    "```\n",
    "> python test_real.py --single_beta --dataset spotify --model_path model/listcvaewithprior_spotify_BS256_dim8_lr0.00030_decay0.00010_0.00001 --device cuda:2\n",
    "```\n",
    "\n",
    "### 2.2 Model with Different Beta\n",
    "\n",
    "```\n",
    "> python test_real.py --all_beta --dataset spotify --model_path model/listcvaewithprior_spotify_BS256_dim8_lr0.00030_decay0.00010 --device cuda:2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206036\n"
     ]
    }
   ],
   "source": [
    "from data_extract import read_yoochoose, encode_yoochoose\n",
    "train,val,test = read_yoochoose()\n",
    "import numpy as np\n",
    "print(len(np.unique(train[\"sessions\"])))\n",
    "# encode_yoochoose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4]\n",
      " [   5    6    5    6    7]\n",
      " [   8    9   10   10   11]\n",
      " ...\n",
      " [6342 3358 6161 3358 2525]\n",
      " [5813 3945 3945 3945 3945]\n",
      " [2657  228  408  229  229]]\n"
     ]
    }
   ],
   "source": [
    "print(train[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38056it [00:00, 191018.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file path:\n",
      "results/spotify_listcvaewithprior_spotify_BS256_dim8_lr0.00030_decay0.00010_0.00001_singlebeta++\n",
      "Load data from \"/home/sl1471/public/spotify/preprocessed/slates.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17960960it [02:03, 145783.87it/s]\n",
      "59736it [00:00, 595180.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from \"/home/sl1471/public/spotify/preprocessed/users.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17960960it [00:49, 363210.13it/s]\n",
      "19096it [00:00, 190958.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from \"/home/sl1471/public/spotify/preprocessed/resps.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17960960it [01:32, 193179.23it/s]\n",
      "69134it [00:00, 691335.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from \"/home/sl1471/public/spotify/preprocessed/train.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14631158it [00:40, 358744.92it/s]\n",
      "97939it [00:00, 505633.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from \"/home/sl1471/public/spotify/preprocessed/val.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1576877it [00:05, 307199.58it/s]\n",
      "133414it [00:00, 645400.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from \"/home/sl1471/public/spotify/preprocessed/test.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1752925it [00:05, 343937.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize dataset\n",
      "Slates shape: (1752925, 5)\n",
      "Users shape: (1752925, 1)\n",
      "Response shape: (1752925, 5)\n",
      "Unique items: 545411\n",
      "Unique users: 39\n",
      "User embedding is used\n"
     ]
    }
   ],
   "source": [
    "import data_extract as dae\n",
    "from data_loader import UserSlateResponseDataset\n",
    "from my_utils import make_model_path, make_result_path, Logger\n",
    "import settings\n",
    "\n",
    "import torch\n",
    "\n",
    "modelPath = 'model/listcvaewithprior_spotify_BS256_dim8_lr0.00030_decay0.00010_0.00001'\n",
    "# place to save test results\n",
    "resultPath = 'results/spotify_listcvaewithprior_spotify_BS256_dim8_lr0.00030_decay0.00010_0.00001_singlebeta'\n",
    "# logger\n",
    "logger = Logger(resultPath)\n",
    "# # test dataset\n",
    "# if args.dataset == \"spotify\":\n",
    "# datasets\n",
    "slates, users, resps, train, val, test = dae.read_spotify()\n",
    "#     testset = UserSlateResponseDataset(slates[test], users[test], resps[test], args.nouser)\n",
    "testset = UserSlateResponseDataset(slates[test], users[test], resps[test], False)\n",
    "# elif args.dataset == \"yoochoose\":\n",
    "#     train, val, test = dae.read_yoochoose()\n",
    "# #     testset = UserSlateResponseDataset(test[\"features\"], test[\"sessions\"], test[\"responses\"], args.nouser)\n",
    "#     testset = UserSlateResponseDataset(test[\"features\"], test[\"sessions\"], test[\"responses\"], args.nouser)\n",
    "# else:\n",
    "#     raise NotImplemented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_users(environment, batch_size):\n",
    "    up = torch.ones(environment.maxUserId + 1)\n",
    "    sampledU = torch.multinomial(up, batch_size, replacement = True).reshape(-1).to(environment.device)\n",
    "    return sampledU\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_coverage(slates, N):\n",
    "    \"\"\"\n",
    "    Item coverage for give slates\n",
    "    @input:\n",
    "     - slates: list of slates\n",
    "     - N: the total number of items in D\n",
    "    \"\"\"\n",
    "    return len(torch.unique(slates)) * 1.0 / N\n",
    "\n",
    "def get_ILS(slates, embeds, normalize = False):\n",
    "    \"\"\"\n",
    "    Intra-List Similarity, diversity can be calculated as (1 - ILS)\n",
    "    @input:\n",
    "     - slates: list of slates\n",
    "     - embeds: nn.Embedding for all possible items\n",
    "    \"\"\"\n",
    "    # obtain embeddings for all items\n",
    "    emb = embeds(slates)\n",
    "    # calculate similarities for each pair of items in each slate\n",
    "    sims = torch.bmm(emb, emb.transpose(1,2)).reshape(slates.shape[0], -1)\n",
    "    if normalize:\n",
    "        sims /= torch.max(sims)\n",
    "    # take the average for each slate\n",
    "    sims = (torch.sum(sims, dim = 1) - slates.shape[1]) / (slates.shape[1] * (slates.shape[1] - 1))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_generative(environment, rec_model, logger, n_trail = 500, batch_size = 32, no_user = False, slate_size = 5):\n",
    "    '''\n",
    "    Generative performance:\n",
    "    @report:\n",
    "    - coverage: the percentage of candidate items that can be recommended\n",
    "    - diversity: slate diversity given by 1 - ILS, where ILS is the intra-list similarity\n",
    "    - enc: expected number of click by interacting with environment\n",
    "    @input:\n",
    "    - environment: the simulator (a.k.a. user response model)\n",
    "    - rec_model: generative recommendation model of type f: (user,)context --> responses\n",
    "    - logger: log file writer\n",
    "    - n_trail: T, number of batch\n",
    "    - batch_size: B, T*B is the total number of generated slates\n",
    "    - no_user: set to True if the generative model takes user id as input\n",
    "    - slate_size: size of slate L, used for setting up ideal responses as context\n",
    "    '''\n",
    "    logger.log(\"Test generative model on environment(user response model)\")\n",
    "    \n",
    "    # generative performance\n",
    "    \n",
    "    diversities = torch.zeros(slate_size)\n",
    "    allGenSlates = [torch.zeros((n_trail * batch_size, slate_size)) for i in range(slate_size)]\n",
    "    expectedNClick = [[] for i in range(slate_size)]\n",
    "    rec_model.set_candidate(False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # repeat for several trails\n",
    "        for k in tqdm(range(n_trail)):\n",
    "            # sample users for each trail\n",
    "            sampledUsers = sample_users(environment, batch_size)\n",
    "            # test for different input condition/context\n",
    "            context = torch.zeros(batch_size, slate_size).to(rec_model.device)\n",
    "            for i in range(slate_size):\n",
    "                # each time set one more target response from 0 to 1\n",
    "                context[:,i] = 1\n",
    "                # recommend should gives slate features of shape (B, L)\n",
    "                if no_user:\n",
    "                    rSlates, z = rec_model.recommend(context, return_item = True)\n",
    "                    resp = environment(rSlates.view(batch_size, -1))\n",
    "                else:\n",
    "                    rSlates, z = rec_model.recommend(context, sampledUsers, return_item = True)\n",
    "                    resp = environment(rSlates.view(batch_size, -1), sampledUsers)\n",
    "                \n",
    "                # diversity = 1 - ILS (intra list similarity)\n",
    "                diversities[i] += torch.mean(-get_ILS(rSlates.view(batch_size, -1), rec_model.docEmbed).detach().cpu() + 1)\n",
    "                # record the slate for calculating item coverage\n",
    "                allGenSlates[i][k*batch_size: (k+1)*batch_size, :] = rSlates.detach().cpu()\n",
    "                # the expected number of click\n",
    "                expectedNClick[i].append(torch.sum(resp).detach().cpu().numpy())\n",
    "        # final calculation of metrics\n",
    "        coverages = []\n",
    "        for i in range(slate_size):\n",
    "            coverages.append(get_coverage(allGenSlates[i], len(rec_model.docEmbed.weight)))\n",
    "        diversities = diversities / n_trail\n",
    "        enc = np.mean(np.array(expectedNClick[i]), axis = 1)\n",
    "    \n",
    "    return {\"coverage\": coverage, \"diversity\": diversities, \"enc\": enc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_test(model_path, testset, resp_model, logger):\n",
    "    '''\n",
    "    Standard test consists:\n",
    "    - a test on realworld dataset with generative and traditional performance metric\n",
    "    - a test on generative performance on the pretrained simulator\n",
    "    '''\n",
    "    device = \"cuda:2\"\n",
    "    recModel = torch.load(open(model_path, 'rb'))\n",
    "    recModel.to(device)\n",
    "    recModel.device = device\n",
    "    resp_model.to(device)\n",
    "    resp_model.device = device\n",
    "#     reports[modelPath] = test_realworld(testset, recModel, logger)\n",
    "    genReports[model_path] = test_generative(resp_model, recModel, logger)\n",
    "    return {k:v for k,v in list(reports.items()) + list(genReports.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load environment (user response) model\n",
    "respModel = torch.load(open('model/resp_[48,256,256,5]_spotify_BS64_dim8_lr0.00030_decay0.00010', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sl1471/anaconda3/lib/python3.7/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.UserListCVAEWithPrior' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test generative model on environment(user response model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f373ac1fcb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testset performance:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6653156217bd>\u001b[0m in \u001b[0;36mstandard_test\u001b[0;34m(model_path, testset, resp_model, logger)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     reports[modelPath] = test_realworld(testset, recModel, logger)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgenReports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenReports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d3e15d3d6a27>\u001b[0m in \u001b[0;36mtest_generative\u001b[0;34m(environment, rec_model, logger, n_trail, batch_size, no_user, slate_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrSlates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mrSlates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampledUsers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrSlates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampledUsers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "reports = standard_test(modelPath, testset, respModel, logger)\n",
    "\n",
    "logger.log(\"Testset performance:\")\n",
    "logger.log(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A = torch.randn(5,3)\n",
    "b = torch.mean(torch.sum(A,1))\n",
    "c = torch.zeros(3)\n",
    "c[0] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0602,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenSlate",
   "language": "python",
   "name": "genslate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
